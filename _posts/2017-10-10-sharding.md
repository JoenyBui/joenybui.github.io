---
reference: https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6
---

# Sharding Strategies

Sharding is a method of splitting and storing a single logical dataset in multiple databases.  Sharding allows the database to scale along with it's traffic.

How the data is read affects your sharding strategy choice?
How the data is distributed affects the storage and performance hotspots.  
Redistributing data is important as you scale.

* Vertical Partition --> storing different ables & columns in separate database
* Horizontal Partitioning (sharding) --> storing same tables in multiple database nodes

![alt text](https://miro.medium.com/max/700/1*yyHih3GveWruzwYgLxTu3w.png)

## Vertical Partiioning 

Done at the application level where there is an obvious split.  If the applications needs read performance (add caches or database replicas).

* Binary Blobs - ususally separated
* Full text search
* Tagging
* Analytics

## Shard Strategies

### Algorithmic Sharding

![Algorithm shard](https://miro.medium.com/max/700/1*fx3wbDDGHo2cgcAvDiHkDg.png)

* uses a sharding function `(partition_key) -> datbase_id`, such as `hash(key) % num_db`.
* distributes data by its sharding function only
* each partition should be similarly sized
* (pros) great for key-value databases with homogeneous values
* (con) resharding is challenging because it requires updating the sharding function and moving data around the cluster
* [consisitent hashing](https://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html)


### Dynamic Sharding

* an external locator service determines the location of entries
* (cons) to read and write data, clients need to consult the locator service first
* (pros) operation onf primary key becomes very trivial
* (pros) more resilient to nonuniform distribution of data
* (cons) locator service (master shard) is the single point of failure
* consensus algorithms and synchronous replications are used to store this data
* HDFS uses a Name Node to store filesystem metadata
