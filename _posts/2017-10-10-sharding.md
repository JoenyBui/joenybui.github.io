---
layout: post
author: Joeny Bui
reference: https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6
---

# Sharding Strategies

Sharding is a method of splitting and storing a single logical dataset in multiple databases.  Sharding allows the database to scale along with it's traffic.

How the data is read affects your sharding strategy choice?
How the data is distributed affects the storage and performance hotspots.  
Redistributing data is important as you scale.

* Vertical Partition --> storing different ables & columns in separate database
* Horizontal Partitioning (sharding) --> storing same tables in multiple database nodes

![alt text](https://miro.medium.com/max/700/1*yyHih3GveWruzwYgLxTu3w.png)

## Vertical Partiioning 

Done at the application level where there is an obvious split.  If the applications needs read performance (add caches or database replicas).

* Binary Blobs - ususally separated
* Full text search
* Tagging
* Analytics

## Shard Strategies

* a logical shard (data sharing the same partition key) must fit in a single node (cannot span multiple nodes)
* sharding data by user over time due to power user located in one shard
* replication is critical

### Algorithmic Sharding

![Algorithm shard](https://miro.medium.com/max/700/1*fx3wbDDGHo2cgcAvDiHkDg.png)

* uses a sharding function `(partition_key) -> datbase_id`, such as `hash(key) % num_db`.
* distributes data by its sharding function only
* each partition should be similarly sized
* (pros) great for key-value databases with homogeneous values
* (con) resharding is challenging because it requires updating the sharding function and moving data around the cluster
* [consisitent hashing](https://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html)


### Dynamic Sharding

![](https://miro.medium.com/max/700/1*9we5WT45G7_unZ6n0N6ncw.png)

* an external locator service determines the location of entries
* (cons) to read and write data, clients need to consult the locator service first
* (pros) operation onf primary key becomes very trivial
* (pros) more resilient to nonuniform distribution of data
* (cons) locator service (master shard) is the single point of failure
* consensus algorithms and synchronous replications are used to store this data
* HDFS uses a Name Node to store filesystem metadata

### Entity Groups

![](https://miro.medium.com/max/700/1*o5Tv6C2bMdBn8U7Lcq3PDw.png)

* store related entities in the same partition
* queries within a single physical shard are efficient
* stronger consistency semantics can be achieved within a shard
* (cons) queries spanning multiple partitions have looser consistency gurantees

### Hierarchical keys & Column-Oriented Database

![Hierarchical keys](https://miro.medium.com/max/500/1*usEoE4YEU-B-_-VOBOSnQA.png)

* Column-oriented databases are a extention of key-value stores
* (pros) allows databases to implement data-agnostic sharding mechanisms and efficient storage engines
* (pros) can model a problem such as (time series)[http://planetcassandra.org/getting-started-with-time-series-data-modeling/] efficiently
